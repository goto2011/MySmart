<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <style>
      body {font-family:'Helvetica Neue', Arial, sans-serif; color:#333; font-size:13px; line-height:17px;}
      body .name,body .note {white-space:pre-wrap;}
      body ul {list-style:disc; margin:0; padding:0;}
      body li {margin:4px 0 4px 20px; padding:0;}
      body>.name {font-size:16px; line-height:21px;}
      body>.note {font-size:13px; line-height:17px;}
      body>ul {margin-top:15px;}
      body .name.done {text-decoration:line-through; color:#999;}
      body .note {font-size:12px; color:#666;}
    </style>
  </head>
  <body>
    <span class="name">AI基本概念</span><ul><li><span class="name">P和NP问题</span><ul><li><span class="name">如果我们能有效解决它，那么这个问题就属于P。</span></li><li><span class="name">如果我们能有效找到其解决方案，那么这个问题属于NP。</span></li><li><span class="name">P=NP的问题就是，能有效找到的问题是否可以得到有效解决。很多问题我们知道我们最终可以解决，但是现在找不到一个时间、成本都可接受的解决方案。这也叫图灵可停机问题。</span></li><li><span class="name">我们感兴趣的问题往往都是NP问题。我们对不困难的问题兴趣都不大（贱啊！）。</span></li><li><span class="name">弄明白蛋白质如何折叠成特定形状；通过DNA来重新构建一系列物种的进化史；在命题逻辑中证明定理；利用交易成本来发现市场中的套利机会；从二维视图中推出三维形状；将数据压缩到磁盘上；在政治活动中组成稳定联盟；在剪切流中模拟湍流；按照给定回报率找出最安全的投资组合、到达几个城市的捷径、微芯片上元件的最佳布局方案、生态系统中传感器的最佳布局、自旋玻璃门最低的能量状态；安排好航班、课程、工厂工作；最优化资源分配、城市交通流、社会福利，以及提高你的俄罗斯方块分数——这些都是NP完全问题，意思是，如果你能有效解决其中的一个问题，就能有效解决所有NP类问题。</span></li></ul></li><li><span class="name">AI的五大学派</span><ul><li><span class="name">符号学派</span><ul><li><span class="name">符号学派将学习看作逆向演绎，并从哲学、心理学、逻辑学中寻求洞见。</span></li><li><span class="name">对于符号学派来说，所有的信息都可以简化为操作符号，知识可以通过符号演算而来。它的主算法是逆向演绎。逆向演绎致力于弄明白，为了使演绎进展顺利，哪些知识被省略了，然后弄明白是什么让主算法变得越来越综合。</span></li><li><span class="name">理性主义者喜欢在迈出第一步前，就提前规划好一切。笛卡儿、斯宾诺莎、莱布尼茨是理性主义的代表。</span></li><li><span class="name">经验主义者喜欢尝试新事物，然后看看结果会怎样。洛克、贝克莱、休谟则是经验主义的代表。其中休谟是最伟大的一个，他也是符号学派的守护神。</span></li><li><span class="name">归纳：在概括我们见过的东西以及没见过的东西时，怎样才能做到合理？（from 休谟）</span></li><li><span class="name">如果我们只是假设未来和昨天一样，那么会怎样呢？这当然是一个有风险的假设。如果没有这样的假设，所有知识将不复存在，生活也是如此。虽然有很多不确定性，但我们还是宁可活下来。</span></li><li><span class="name">但是，困境依然存在：总有一些现象我们从未见过。这属于机器学习问题：将某结果推广到我们没有见过的事件中。</span></li><li><span class="name">大卫·沃尔珀特（DavidWolpert）赋予了这个问题优雅的数学形式。他的研究结果被人们称为“天下没有免费的午餐”定理，规定“怎样才算是好的学习算法”：没有哪个学习算法可以比得上随意猜测。</span></li><li><span class="name">这个定理告诉我们：不靠知识进行学习，这样的事不存在；只有数字也不够。</span></li><li><span class="name">预设观念对人类认知来说，也是必不可少的，这些观念是“直线布入”人脑的。对于它们，我们也觉得是理所当然的。超出那些观念的偏见才值得质疑。</span></li><li><span class="name">我们的目标是找到最简单的、我们能编写的程序，这样写好的程序就可以无限制地通过阅读数据来自行编程，直到该程序掌握所有能掌握的知识。</span></li><li><span class="name">如果所有两个因素组合的预测都失败了，你可以尝试任意个数因素的组合，机器学习者和心理学家称之为“合取概念”（conjunctiveconcept）。首先做有条件的假设，如果这样无法解释数据，再放松假设的条件，这就是典型的机器学习。这个过程通常由算法自行进行，不需要你的帮助。首先，算法会尝试所有单一因素，然后尝试所有两个因素的组合，之后就是所有三个因素的组合等。但现在我们遇到一个问题：合取概念太多，没有足够的时间对其逐个尝试。</span></li><li><span class="name">客观世界上的事物有个最大的特点就是涉及的因素很多，比如要做一个恋爱速配的算法，人的度量维度很容易就会扩展到100项（这算非常少的了），也就是组合关系有3的100次方种（是、否、无关）。做一次全排列电脑要计算到宇宙末日（其实远远超过宇宙末日）。</span></li><li><span class="name">这里有一种方法：暂且假设每个配对都合适，然后排除所有不含有某品质的搭配，对每种品质重复同样的做法，然后选择那个排除了最多不当搭配和最少适当搭配的选项。</span></li><li><span class="name">我们学习每个规则之后，会排除该规则包含的正面例子，因此下一个规则会尽可能多地包含剩下的正面例子，以此类推，直到所有的例子都被包含在内。</span></li><li><span class="name">记住“天下没有免费的午餐”：没有知识，你就无法进行学习。假设某概念能通过规则集来定义，相当于什么也没有假设。</span></li><li><span class="name">学习就意味着将细节遗忘，只记住重要部分。</span></li><li><span class="name">问题不限于记忆大量例子。每当算法在数据中找到现实世界世界中不存在的模型时，我们说它与数据过于拟合。过拟合问题是机器学习中的中心问题。在所有主题中，关于过拟合问题的论文最多。每个强大的学习算法，无论是符号学算法、联结学算法，或者其他别的学习算法，都不得不担忧幻觉模式这个问题。避免幻觉模式唯一安全的方法，就是严格限制算法学习的内容，例如要求学习内容是一个简短的合取概念。很遗憾，这种做法就像把孩子和洗澡水一起倒掉一样，会让学习算法无法看到多数真实的模型，这些模型在数据中是可见的。因此，好的学习算法永远在无知与幻觉的夹缝中行走。</span></li><li><span class="name">学习算法特别容易过拟合，因为它们拥有从数据中发现模型、近乎无限制的能力。人类发现一个模型所用的时间，计算机可以找到数百万个。在机器学习中，计算机最大的优势（处理大量数据以及不知疲倦不断重复同样步骤的能力）也是它的劣质所在。</span></li><li><span class="name">甚至曾有人说过，数据挖掘意味着“折磨数据，直到数据妥协”。</span></li><li><span class="name">当你有过多假设，而没有足够的数据将这些假设区分开来时，过拟合问题就发生了。</span></li><li><span class="name">在机器学习中，一个概念可能实例的数量，是其属性数量的指数函数：如果属性是布尔值，每种新的属性可能会是实例数量的两倍，方法就是引用之前的每个实例，然后为了那个新属性，对该实例以“是”或“非”来进行扩展。反过来，可能概念的数量是可能实例数量的指数函数：既然每个概念都把实例分成正面或者负面，加入一个实例，可能的概念就会翻倍。因此，概念的数量就是属性数量的指数函数的一个指数函数！换句话说，机器学习就是组合爆炸的组合爆炸。</span></li><li><span class="name">幸运的是，一个真实的数据可以排除指数数量的假设。</span></li><li><span class="name">总结：学习就是你拥有的数据的数量和你所做假设数量之间的较量。</span></li><li><span class="name">如果一个随机定义准确匹配了1000个例子，那么这个概念不太有可能是错误的定义，或者至少它和正确的定义非常接近。而且如果一个定义和100万个例子相匹配，那么实际上它就是正确的定义。</span></li><li><span class="name">一般来说，如果学习算法只做了一个指数数量的假设（例如，所有可能的合取概念），那么该数据的指数报酬会将其取消，你毫无影响，只要你有许多例子，且属性不太多。</span></li><li><span class="name">如果算法做了一个双指数的假设（例如，所有可能的规则集），那么数据只会取消其中的一个指数，而且你仍会处于麻烦之中。</span></li><li><span class="name">哈佛大学的莱斯利·瓦利安特获得了图灵奖，因为他发明了这种分析方法，他在自己的书中将这种方法取名为“可能近似正确”（probably approximately correct），非常恰当。</span></li><li><span class="name">在实践中，瓦利安特式的分析方法需要的数据还是要比你拥有的多。那么如何信任算法告诉你的结论呢？很简单，理论必须做出新的预测，而且只有这些预测经过实验验证后，你才接受它们。</span></li><li><span class="name">你可以利用自己拥有的数据，将其分成一个训练集和一个测试集，然后前者交给学习算法，把后者隐藏起来不让学习算法发现，用来验证其准确度。留存数据的准确度就是机器学习中的“黄金标准”。</span></li><li><span class="name">对于机器学习来说，对不可见数据的测试是必不可少的，因为这是判断学习算法是否过拟合的唯一方法。</span></li><li><span class="name">运用统计显著性检验来确保我们看到的模型真实可靠。</span></li><li><span class="name">“分而治之”算法会含蓄地选择更简单的规则，因为它在一出现只有正面例子的情况时，就会停止添加条件；在一出现包含所有正面例子的情况时，就会停止添加规则。</span></li><li><span class="name">奥卡姆剃刀原理可能是错的。简单的理论更受欢迎，因为它们对于我们来说，花费的认知成本更低；对于我们的算法来说，花费的计算成本更低，这不是因为我们想让这些理论更准确。我们由“天下没有免费的午餐”这个定理，知道没有什么能够保证最简单的理论最擅长概括，而实际上，有些最佳的学习算法，比如推进和支持向量机，能了解那些看起来过于复杂的模型。</span></li><li><span class="name">如果得到的检测集不够准确，问题可能存在两方面：</span></li><li><span class="name">偏差：某座钟如果总是慢一个小时，那么它的偏差会很高，但方差会很低。</span></li><li><span class="name">反差：但如果这座钟走得时快时慢，时快时慢，最后平均下来准点了，那么它的方差会很高，但偏差会很低。</span></li><li><span class="name">你可以估算一种学习算法的偏差和方差，方法就是在掌握训练集的随机变量之后，对算法的预测进行对比。</span></li><li><span class="name">如果算法一直出错，那么问题就出在偏差上，而你需要一个更为灵活的学习算法（或者只和原来的不一样即可）。</span></li><li><span class="name">如果出现的错误无模式可循，问题就出在方差上，而你要么尝试一种不那么灵活的学习算法，要么获取更多的数据。</span></li><li><span class="name">大多数学习算法都有一个“把手”，通过旋转“把手”，你可以调节这些算法的灵活度，例如，显著性检验的界限值，或者对于模型规模的惩罚方式。扭动“把手”是你尝试的第一个选择。</span></li><li><span class="name">更深层的问题是，多数学习算法开始时掌握的东西很少，即使转再多“把手”，也没法让这些算法到达终点。主算法应该能以大量的知识作为启动（无论这些知识由人类来提供，还是之前已经掌握），然后在对数据做出新概括时，用到这些知识。“分而治之”算法做不到这一点，但是有其它方法。问题的关键在于认识到，归纳仅仅是逆向演绎，就和减法是加法的逆运算，或者积分是微分的逆运算一样。</span></li><li><span class="name">演绎推理的一个典型例子就是：苏格拉底是人类。所有人类都会死。所以……</span></li><li><span class="name">相反，我们在归纳推理中会以最初事实和衍生事实作为开始，然后找一个规则，让我们由前者推出后者：苏格拉底是人类。……所以苏格拉底也会死。</span></li><li><span class="name">缺的那一环是：所有人类都会死。当然，仅通过苏格拉底就归纳出该规则过于草率，但对于其他人类，我们知道相似的事实：柏拉图是人类，他会死。亚里士多德是人类，他会死。以此类推……对于每个事实，我们构建这样的规则，让我们由第一个事实推出第二个事实，然后通过牛顿定律将其推广。当同一条通用规则一次又一次被归纳出来时，我们有信心说那条规则说的是真的。</span></li><li><span class="name">我们以越多的规则和事实作为开头，也就有越多的机会运用“逆向演绎”归纳新的规则。我们归纳的规则越多，我们能归纳的规则也就越多。这是知识创造的良性循环，只受过拟合风险和计算成本的限制。</span></li><li><span class="name">逆向演绎的另外一个局限性就在于，它涉及很密集的计算，因此很难扩展到海量数据集中。因为这些原因，符号学家选择的算法是决策树归纳。</span></li><li><span class="name">有一个方法，就是对规则进行排序，例如以准确率递减的顺序来排列，然后选择符合描述的第一条规则。另一个方法，就是让规则自己选择。决策树通常会保证，每个实例会准确对应一条规则。也就是说，在一次及以上的属性测试中，如果每对规则存在区别，这样的规则集将被组织成一棵决策树。</span></li><li><span class="name">看看以下这些规则：如果你支持削减税收，反对堕胎，那么你属于共和党。如果你反对削减税收，那么你属于民主党。如果你支持削减税收，提倡堕胎合法，反对枪械管制，那么你属于独立人士。如果你支持削减税收，提倡堕胎合法，支持枪械管制，那么你属于民主党。这些可以组成一些决策树。</span></li><li><span class="name">拥有这个属性的概念组被称为类集，而预测类集的算法称为分类器。单个概念隐含两类定义：概念本身及其反面。分类器是机器学习最为普遍的方式。</span></li><li><span class="name">有一个突出的问题，那就是如何挑选最佳属性以便在节点处进行测试。为了学习一棵好的决策树的优点，我们在每个节点选择这样这样的属性：在其所有分支中，产生的熵在平均值上属性最低，取决于每个分支上有多少例子。</span></li><li><span class="name">如果属性离散，属性的每个值都有一个分支，这没关系，但如果是数值属性该怎么办？如果连续变量的每个值都有一个分支，决策树将变得无限宽。一个简单的方法就是通过熵来选择几个临界值，然后使这些临界值起作用。</span></li><li><span class="name">决策树易于理解，可以快速掌握，而且通常无须太多调整就可以做到准确无误。所以决策树已经发展成为机器学习算法中应用最为广泛的方法。微软的Kinect利用决策树，通过其深度相机的输出信息，可以弄明白你身体的各个部位在哪里，然后利用这些部位的动作来控制Xbox游戏机。</span></li><li><span class="name">如何选择根？</span></li><li><span class="name">心理学家大卫·马尔称，每个信息处理系统应该经过三个不同水平的研究：该系统所解决问题的基本属性，用来解决问题的算法和表示方法，以及这些算法和表示方法如何实现。</span></li><li><span class="name">符号主义是通往终极算法的最短路程。它不要求我们弄明白进化论和大脑的工作原理，而且也避免了贝叶斯主义的数学复杂性。规则集合决策树易于理解，所以我们知道学习算法要做什么。这样它可以轻易算出自己做对或做错什么，找出故障，得出准确结果。</span></li><li><span class="name">尽管决策树很受欢迎，但逆向演绎是寻找主算法更好的出发点。因为逆向演绎具备这样的关键属性：可以轻易地将知识并入主算法中，而且我们知道休谟问题使这一点变得很有必要。</span></li><li><span class="name">把一棵决策树转变成一个规则集很容易：每条从“根部”到“叶子”的路线是一条规则，而且路线不会崩溃。</span></li><li><span class="name">联结学派对符号学派尤其不满。根据他们的观点，你能通过逻辑规则来定义的概念仅仅是冰山一角，其实表面之下还有很多东西是形式推理无法看到的。而同样的道理，我们脑子里所想的东西也是潜意识的。</span></li></ul></li><li><span class="name">联结学派</span><ul><li><span class="name">联结学派对大脑进行逆向分析，灵感来源于神经科学和物理学。</span></li><li><span class="name">对于联结学派来说，学习就是大脑所做的事情，因此我们要做的就是对大脑进行逆向演绎。大脑通过调整神经元之间连接的强度来进行学习，关键问题是找到哪些连接导致了误差，以及如何纠正这些误差。联结学派的主算法是反向传播学习算法，该算法将系统的输出与想要的结果相比较，然后连续一层一层地改变神经元之间的连接，目的是为了使输出的东西接近想要的东西。</span></li><li><span class="name">赫布律，是联结主义的奠基石。联结主义相信知识储存在神经元之间的联结关系中。</span></li><li><span class="name">在符号学派中，符号和它们代表的概念之间有一一对应的关系。相反，联结学派的代表方式却是分散式的：每个概念由许多神经元来表示，而每个神经元又会和其他神经元一起代表许多不同的概念。互相激发的神经元会形成赫布所称的“细胞集”。</span></li><li><span class="name">一个神经元就有数千个突触。</span></li><li><span class="name">每个神经元就像一棵小树，有数目惊人的根须（树突）还有细长蜿蜒的树干（轴突）。大脑就是由数十亿棵这样的树组成的森林，但这些树也有不同寻常的地方：每棵树的枝丫都会和其他数千棵树的根部有连接（突触），形成大片你没见过的纠缠状态。有些神经元有很短的轴突，而有些神经元的轴突则很长，可以从大脑的一边缠绕到另一边。你大脑里轴突的长度相当于地球到月亮的距离。</span></li><li><span class="name">感知器不能处理XOR（异或）关系。</span></li><li><span class="name">问题在于，没有明确的方法来改变“隐层”中神经元的权值，以减少输出层中神经元造成的误差。每个隐藏的神经元会通过多种路线来影响输出量，而且造成每个误差的原因也可能达到上千种。你该责怪谁？或者，相反，谁该因为正确的输入量而受到赞扬？这个问题在我们努力对一个复杂模型进行学习时随时会出现，而这个问题也是机器学习领域中的中心问题。</span></li><li><span class="name">霍普菲尔德注意到自旋玻璃和神经网络之间有趣的相似点：一个电子的自旋对其相邻电子的活动所做的反应和一个神经元的反应十分相似。在电子的情况中，如果相邻电子的加权和超过界限值，电子就会向上翻，反之则向下翻。受到这一点的启发，他确定了一种神经网络，和自旋玻璃一样随着时间的推移而演变，他还提出网络的最低值状态就是它的记忆。每个这样的状态都具备原始状态的“吸引盆”（basinofattraction），原始状态就收敛于该盆中，这样这个网络就可以进行模式识别了。例如，如果其中的一个记忆是由数字9形成的黑白像素模式，而网络看到一个扭曲了的9，它会收敛成“理想”的9，然后据此重新识别它。</span></li><li><span class="name">一台玻尔兹曼机器拥有混合的感官和隐藏神经元（分别类似于视网膜和大脑）。它通过清醒和睡眠两种交替状态进行学习，就像人类一样。</span></li><li><span class="name">玻尔兹曼机器原则上可以解决赞誉分布问题，但在实践中，学习这个行为非常缓慢且痛苦，对大多数应用来说，玻尔兹曼机器有点不切实际。</span></li><li><span class="name">学习算法的“视网膜”看到一张新的图片，这个信号就会在网络中传播，直到它产生输出信息。将这条输出信息和理想的输出信息相比，会发出错误信号，这个信号会穿过神经元层，然后反向传播回去，直到它到达视网膜。根据返回来的信号以及在前进过程中它接收到的输入信息，每个神经元会调整各自的权值。随着网络看到越来越多你祖母和其他人的照片，权值会逐渐收敛到能够让它区分两者的值中。反向传播，比感知器算法要强大很多。</span></li><li><span class="name"><b>反向传播是联结学派的主算法。</b></span></li><li><span class="name">有了反向传播，你就不必从头开始弄明白怎样对每个神经元的权值进行微调，这样做起来会很慢。你可以一层一层来做，根据调整与其相连神经元的方法，来调整每个神经元。</span></li><li><span class="name">反向传播的弱点：反向传播随着渐进权值的变化，不知道该如何找到全局误差最小值，而局部误差值可能会很糟糕。</span></li><li><span class="name">但我们最好意识到的是，多数情况下局部最小值挺好的，不会有不良影响。</span></li><li><span class="name">更好的消息是，实际上，局部最小值可能更适合，因为它和全局最小值比，不太可能证明对我们的数据过拟合。</span></li><li><span class="name">如今联结学派又复活了。我们比现在掌握了更深层的网络，而且这些网络在视觉、语音识别、药物研制和其他领域都在设定新标准。</span></li><li><span class="name">往发动机盖下面看……惊喜：是值得信赖的老式反向传播发动机还在嗡嗡作响。什么发生改变了？评论家说，没什么大的改变：只是计算机变得更快了，数据变得更大了。</span></li><li><span class="name">下一个聪明的主意就是把稀疏自动编码器逐个堆积起来，就像一个多层三明治那样。第一个自动编码器的隐藏层变成第二个的输入或输出层，依此类推。因为神经元是非线性的，每个隐藏层会掌握输入层更为复杂的表达方式，在前一个隐藏层的基础上进行进行构建。给定大批的面部图片，第一个自动编码器会对局部特征，如棱角和斑点进行编码；第二个自动编码器利用这些信息来对诸如鼻尖、眼睛的虹膜这些面部特征进行编码；第三个掌握整个鼻子和眼睛的面部特征等。最终，最顶端的一层可以是一台传统的感知器，会通过下一层编码器提供的上层特征来识别你的祖母，这和只利用单个隐藏层提供的粗糙信息，以及对所有层进行反向传播相比，要简单得多。</span></li><li><span class="name">登上《纽约时报》的谷歌大脑网络是一个由自动编码器和其他材料组成的9层三明治，能够从视频网站YouTube的视频中识别出猫。它包含数十亿个连接，是当时能够进行学习的最大网络。不足为奇的是，吴恩达（该项目的主要负责人之一）也是支持“人类智能可以归结为单个算法”这个思想的主要人物。</span></li><li><span class="name">叠加自动编码器不是唯一的深度学习算法，另外一种以玻尔兹曼机器作为基础，还有一种——卷积神经网络，则把视皮质模型作为基础。</span></li><li><span class="name">我们不会通过对羽毛进行逆向工程来制造飞机。</span></li><li><span class="name">一些人认为，反向传播就是终极算法。但符号学派的人不认可，有很多人能做但是联结系统不能做的事。按照常识进行推理，这就涉及把之前从来没有被放在一起的信息组合在一起。玛丽午饭吃鞋子吗？不，因为玛丽是人，人类只吃能吃的东西，而鞋子不能吃。符号系统做到这些没有问题——它只会把相关规则串起来，但是多层感知器却做不到这一点。一旦完成学习，它只会不断计算同一个指定函数。神经网络不是组合出来的，而语意合成性是人类认知的一大部分。</span></li><li><span class="name">另外一个大问题就是人类，以及诸如规则集和决策树之类的符号模型，可以对它们的推理进行解释，而神经网络是一大堆没人能看懂的数字。</span></li></ul></li><li><span class="name">深度学习属于联结学派. </span></li><li><span class="name">进化学派</span><ul><li><span class="name">进化学派在计算机上模拟进化，并利用遗传学和进化生物学知识。</span></li><li><span class="name">进化学派认为一切学习都源于自愿选择。选择造就我们，也造就一切。进化主义解决的关键问题是学习结构：不只是像反向传播那样调整参数，它还创造大脑，用来对参数进行微调。进化学派的主算法是基因编程，和自然使有机体交配和进化那样，基因编程也对计算机程序进行配对和提升。</span></li><li><span class="name">遗传算法的关键输入就是一个适应度函数。给定一个待定程序和某个设定的目标，适应度函数会给程序打分，反映它与目标的契合度。</span></li><li><span class="name">在自然选择当中，适应度是否能这样解释，值得怀疑：虽然翅膀对于飞行的适应度很高，这个说法很直观，但整个进化过程却没有已知的目标。即便如此，在机器学习中，掌握诸如适应度函数这样的事情还是很容易的。如果我们需要一个能够诊断疾病的程序，如果一种算法能够正确诊断我们数据库中60%的病人，这样的算法就比准确率仅为55%的算法要好，所以可行的适应度函数能够帮助准确诊断。</span></li><li><span class="name">就这一点而言，遗传算法就有点像选择育种。</span></li><li><span class="name">变量，无论在DNA序列中，还是在位串中，都可通过几种方法产生。最简单的方法就是点突变，即随意翻转位串中的一个比特值，或者改变一段DNA中的单个基本碱基。但对霍兰德来说，遗传算法的真正威力在于更为复杂的东西：性。</span></li><li><span class="name">遗传算法通过模拟这个过程发挥作用。它为每一代中两个适应力最强的个体进行配对，通过随机交叉父母位串中的一点，让每对父母生出两个后代。将点突变应用到新的位串后，算法让这些点突变在其虚拟世界中释放。每个点突变都会反馈适应度得分，然后重复这个过程。每一代都会比前一代的适应度更高，当达到理想的适应度或者时间用尽时，这个过程就会结束。</span></li><li><span class="name">遗传算法能够频繁作弊的方法，就是允许有永不灭亡的东西（现实生活中却不存在，太糟了）。在那种方法中，适应力很强的个体不仅会在它那一代中为了繁殖而竞争，还会跟它的“儿子”“孙子”“重孙”等竞争，只要在群体中还保留有其中一个适应力最强的个体。</span></li><li><span class="name">一旦算法达到适应度的局部最大值（适应度中的峰值），算法会在这一点停很长时间，直到某次幸运的变异或者交叉，让处于坡上的个体等到更高的峰顶，在这一点上该个体会进行大量繁殖，然后和过往的每一代来爬上这个坡。</span></li><li><span class="name">遗传算法的灵活之处就在于，每个字符串都暗含指数数量的构造块，被称为“基模”，因此该研究比它看起来的还要高效得多。</span></li><li><span class="name">霍兰德表明，和平均值相比，在某代中表示基模的字符串适应度越高——我们能期望的——在下一代中看中看到这些表示字符串的数量也越多。随着时间的流逝，适应度更高的基模会主导群体，所以不像醉汉那样，遗传算法能找到回家的路。</span></li><li><span class="name">机器学习中最重要的问题之一（也是关于生命最重要的问题之一），就是探索—利用困境。</span></li><li><span class="name">遗传算法还有一个很大的谜团没有解开：性在进化过程中所起的作用。演化新论者论者非常重视交叉行为，但其他学派的成员认为没有必要如此麻烦。霍兰德没有哪个理论结果表明，交叉行为能起作用。</span></li><li><span class="name">随着模块演变得越来越大，交叉行为也会越来越趋向于将这些模块解散。</span></li><li><span class="name">还有，一旦适应力强的个体出现，其后代很有可能快速掌管该群体，并有可能将更好的基模挤出，这些基模受到整体上不那么相配的个体的牵绊。</span></li><li><span class="name">消除性别对于演化新论者来说，就只剩下变异作为其理论的推动力。如果群体的规模大体上比基因的数量大，很有可能每个点突变都已体现在其中，而研究就变成爬山法的一种：尝试所有可能的单步变种，挑选最好的一个，然后重复这个步骤（或者挑选几个最好的变种，这种情况就被称为“定向搜索”）。</span></li><li><span class="name">应特别指出的是，符号学派一直用这种方法来掌握规则集，虽然他们不把它当成进化的一种形式。为了避免陷入局部最大值的陷阱，爬山法可以通过随机性（以某个概率做下坡移动）和随机重启（过一会儿后，跳到随机状态，然后从那儿继续）来得到加强。这样做已经足以找到解决问题的好办法。</span></li><li><span class="name">没人知道为什么性别在自然界中无处不在。人们已经提出几个理论，但没有一个被广泛接受。这方面的领先理论是“红皇后”假说，马特·里德利在同名书中向人们介绍该理论。在《爱丽丝镜中世界奇遇记》中，红桃皇后对爱丽丝说：“全力奔跑，这样你才能留在原地。”依照这个观点，有机体和寄生虫就会永远处在竞赛中，而性可以保持群体的多样性，这样单一微生物就不会感染整个群体了。如果这就是答案，那么性就和机器学习不相关。</span></li><li><span class="name">演化新论者和联结学派重要的共同点是：他们都因为受到自然启发而设计了学习算法，不过后来分道扬镳了。演化新论者关注的是学习架构，对他们来说，通过参数优化来对演化的架构进行微调，这是次重要的事情。相反，联结学派更喜欢用一个简单、手工编写的结构，加上许多连接行为，然后让权值学习来完成所有工作。</span></li><li><span class="name">这就是机器学习版本关于先天和后天的争论，而且双方都有很好的论据。</span></li><li><span class="name">在先天与后天之争中，两方都没有完整的答案，关键在于找到如何将两方结合起来。终极算法既不是遗传编程，也不是反向传播，但它得包含这两者的重要部分：结构学习和权值学习。在传统观点看来，先天自然完成第一部分（进化大脑），后天培育再将大脑填满信息。我们可以在学习算法中重复这个过程。</span></li><li><span class="name">新生大脑已经对环境的特点进行编码，但不是很明显，进化过程会将大脑优化，从预期的输入信息中提取那些特点。</span></li><li><span class="name">谁学得最快，谁就会赢。</span></li><li><span class="name">进化寻求好的结构，而神经学习则填满这些结构：这样的结合是我们走向终极算法最简单的一步。</span></li><li><span class="name">“自然”（先天）对计算机来说就是它运行的程序，而“人工”（后天）则是获取的数据。（说得太对了！）“这两个哪个重要”这样的问题明显有点荒唐。</span></li><li><span class="name">机器学习是地球上生命之间竞争的最新篇章，更加快速的硬件只是等式的一边，另一边是更加智能的软件。</span></li><li><span class="name">进化的产物有很多明显的错误。</span></li><li><span class="name">活细胞的分子生物学原理非常混乱，分子生物学家常常自嘲道，只有对分子生物学一点也不懂的人才会相信智能设计。</span></li><li><span class="name">与联结学派及演化新论者相反，符号学派和贝叶斯学派不相信“法自然”的说法。</span></li><li><span class="name">对于治疗癌症的问题，原则上，我们可以掌握细胞新陈代谢网络的完整模型，方法就是结合结构研究，利用或者不利用交叉，通过反向传播来进行参数学习，但有太多不利的局部最优陷阱。</span></li><li><span class="name">我们得利用更大块的数据来进行推理，根据需要集合或重新集合这些数据，然后利用逆向演绎来填补空缺。这就是贝叶斯方法。</span></li></ul></li><li><span class="name">贝叶斯学派</span><ul><li><span class="name">贝叶斯学派认为学习是一种概率推理形式，理论根基在于统计学。</span></li><li><span class="name">贝叶斯学派最关注的问题是不确定性，所有掌握的知识都有不确定性，而且学习知识的过程也是一种不确定的推理形式。那么问题就变成，在不破坏信息的情况下，如何处理嘈杂、不完不完整甚至自相矛盾的信息。解决的办法就是运用概率推理，而主算法就是贝叶斯定理及其衍生定理。贝叶斯定理告诉我们，如何将新的证据并入我们的信仰中，而概率推理算法尽可能有效地做到这一点。</span></li><li><span class="name">贝叶斯定理：P(A∣B)=P(A)P(B∣A)/P(B)。</span></li><li><span class="name">贝叶斯定理之所以有用，是因为通常给定原因后，我们就会知道结果，但我们想知道的是已知结果，如何找出原因。</span></li><li><span class="name">贝叶斯公式本身没有什么问题。争议在于相信贝叶斯定理的人怎么知道推导该定理的各个概率，以及那些概率的含义是什么。</span></li><li><span class="name">贝叶斯学派的回答是：概率并非频率，而是一种主观程度上的信任。</span></li><li><span class="name">因此，用概率来做什么由你决定，而贝叶斯推理让你做的事就是：通过新证据来修正你之前相信的东西，得到后来相信的东西（也被人们称为“转动贝叶斯手柄”）。</span></li><li><span class="name">所有模型都是错的，但有些却有用。</span></li><li><span class="name">这时我们就与宿敌再次交锋：组合爆炸问题。</span></li><li><span class="name">如果学习算法利用贝叶斯定理，且给定原因时，假定结果相互独立，那么该学习算法被称为“朴素贝叶斯分类器”。</span></li><li><span class="name">彼得·诺尔维格（谷歌的研究主任）一度告诉我，这（指“朴素贝叶斯法”）是谷歌应用最为广泛的算法，谷歌的机器学习在每个角落都利用了该算法的功能。</span></li><li><span class="name">在任意贝叶斯网络中也是同样的道理：为了获得完整状态的概率，只需将单个变量表格中相应行上的概率相乘。因此，只要条件独立性有效，转换到更加简洁的表示方法不会导致信息丢失。</span></li><li><span class="name">独立性：每个生命都相互关联，但只是间接关联。</span></li><li><span class="name">空间是所有事情没有都发生在你身上的原因。</span></li><li><span class="name">因为对于贝叶斯学派来说，学习只是另一种形式的概率推理。</span></li><li><span class="name">实际上，对于贝叶斯学派来说，没有所谓的真相。</span></li><li><span class="name">你有一个优先于假设的分布，在见到数据后，它变成了后验分布，这是贝叶斯定理给出的说法，也就是贝叶斯定理的全部。</span></li><li><span class="name">就像玩笑说的那样，加入贝叶斯学派意味着绝不用说你对某事很肯定。</span></li><li><span class="name">对于贝叶斯学者来说，概率是包含主观程度的信任，所以他可以自由地做有根据的猜测，而且推理演算会使他所有的猜想都一致。</span></li><li><span class="name">类推学派用这种推理方式得出其逻辑结论，正如我们在第七章将看到的那样。在21世纪的前10年，他们反过来接管NIPS。现在联结学派打着深度学习的旗号再次占据主导地位。</span></li><li><span class="name">逻辑无法处理不完整或包含嘈杂因素的信息，这在实验生物学中较普遍，但贝叶斯网络可以沉着地处理这个问题。</span></li><li><span class="name">逻辑和概率，把它们整合起来很困难。</span></li><li><span class="name">到目前为止，我们谈到的所有学派有一个共同点：共同点：他们都学习研究中的现象的显式模型，无论它是一组规则、一个多层感知器、一个基因计划，还是一个贝叶斯网络。当他们没有足够的数据来做这件事时，就会被难住。但类比学派可以从甚至小到一个例子的数据中学习，因为他们绝不会形成一种模式。</span></li></ul></li><li><span class="name">类推学派</span><ul><li><span class="name">类推学派通过对相似性判断的外推来进行学习，并受心理学和数学最优化的影响。</span></li><li><span class="name">对于类推学派来说，学习的关键是从看似有很大差别的情形中认识到相似性，然后由此推导出其他相似性。如果两个病人有相似的症状，那么也许他们患有相同的疾病。问题的关键是，如何判断两个事物的相似程度。类推学派的主算法是支持向量机，主算法找出要记忆的经历，以及弄明白如何将这些经历结合起来，用来做新的预测。</span></li><li><span class="name">也许在未来10年，机器学习会被深度类比统治，在某种算法中，与最近邻法的高效、支持向量机的数学精密性、类比推理的力量和灵活性结合（瞧，我又泄露了自己的一个秘密研究计划）。</span></li><li><span class="name">通常科学家们利用线性回归来预测连续变量，但大多数现象是非线性的。幸运的是，从局部来看，它们是线性的，因为平滑曲线可以局部近似为直线。因此如果你只用直线来对查询点附近的点，而不是尝试对所有的数据都进行拟合，那么你现在就能拥有一个非常强大的非线性回归算法。懒惰也会有回报。</span></li><li><span class="name">如果肯尼迪需要一套完整的国际关系理论来决定该如何应对苏联在古巴部署的导弹，他可能会遇到麻烦。相反，他从这个危机与第一次世界大战的爆发之间找到相似点，而这个相似点指引他做了正确的决定。</span></li><li><span class="name">利用多个k最近邻而不仅一个近邻，这不是事情的结局。直观来看，与测试例子最接近的例子应该更重要。这让我们引出加权k最近邻算法。</span></li><li><span class="name">最近邻算法是史上第一个能够利用不限数量的数据来掌握任意复杂概念的算法。</span></li><li><span class="name">当今算法要掌握数千甚至数百万个属性并不稀奇。对于电子商务网站来说，它要掌握你的喜好，那么你每点击一下鼠标就算一种属性。网页上的每个词、图片上的每个像素也是如此。</span></li><li><span class="name">实际上，没有哪种算法能够幸免于维数灾难。这是机器学习中，继过拟合之后，第二个最糟糕的问题。</span></li><li><span class="name">要处理弱相关的属性，一个选择就是掌握属性权值。我们不会让所有维度下相似性的重要性相等，而是“缩减”不那么相关的属性。</span></li><li><span class="name">平均数会被加权，而支持向量机只会记住那些用于确定边界的关键例子。</span></li><li><span class="name">这些例子被称为支持向量，因为它们是“支撑”边界的向量：移动一个向量，边界的一段就会滑向其他不同的地方。</span></li><li><span class="name">两个东西如果在一些方面意见一致，那么它们就是相似的。如果它们在一些方面意见一致，可能在其他方面也会意见一致，这就是类比的本质。它还表明了类比推理中的两大子问题：弄明白两个事物的相似度，确定由它们的相似度还能推导出什么。</span></li><li><span class="name">在任何类比学习算法中，最重要的问题就是如何度量相似性。</span></li><li><span class="name">类比推理的第二部分，就是弄明白在已经发现的相似点的基础上，如何推导出新的东西。</span></li><li><span class="name">如果科普是对的，创造性（最深不可测的东西）都可以归结为类比和重组。</span></li><li><span class="name">我们见过的所有学习算法，都需要一位老师来告诉它们正确答案。而人类会无师自通，从出生那天开始，就已经这么做了。</span></li></ul></li><li><span class="name">终极算法</span><ul><li><span class="name">终极算法依赖上述5种算法的综合。现有知识积累依赖符号学派予以数字化，让电脑能够理解；通过联结学派和进化学派寻找解决问题的基本框架；即使这样，我们的知识和面对的问题相比，还是非常不完整的，所以要依赖贝叶斯学派在不确定的局面下寻求方案；而在最困难的情况下，以上做法都失败了，我们还可以通过类推学派，在看似完全不相关的事物间寻找相似点，将彼之方案用于此上，以寻找突破点。</span></li><li><span class="name">我们需要一种能够自发将所有相似物体或者同一物体的不同图片集中起来的算法。这就是聚类问题，这在机器学习当中也是人们研究最多的主题之一。</span></li><li><span class="name">尽管这样的平均值很有用，但我们可以做得更好。的确，大数据和机器学习的全部要点在于避免粗糙的思考。</span></li><li><span class="name">因此罗比面临的是鸡和蛋的问题：如果它知道物体的类别，就可以通过数数的方式来掌握类别的模型；如果它知道模型，可以推断物体的类别。我们好像又遇到困难了，但远非如此：只要在开始时，以你喜欢的方式来猜测每个物体的类别（即使是随机的），然后你就有的忙了。从那些类别和数据中，你可以掌握类别模型；在这些模型的基础上，你可以重新推导类别，以此类推。乍一看，这看起来像一个疯狂的计划：它可能绝不会结束，而是处在由模型推断类别，到由类别推断模型的永恒循环中。即使它停止了，也没有理由相信会停在有意义的集群上。但1977年，来自哈佛大学的三个统计学家（亚瑟·邓普斯特、南·莱尔德、唐纳德·鲁宾）表明，这个疯狂的计划其实可以生效：每次我们绕着圈走时，集群模型就会变得更好，而当模型是可能性的一个局部最大值时，循环结束。他们称该计划为期望最大化演算法（ExpectationMaximization，EM算法），其中E表示期望（推断预期的概率），而M代表最大化（估算可能性最大的参数）。他们还表明，许多之前的算法都是EM的特殊情况。</span></li><li><span class="name">无论何时，当我们想掌握某个统计模型，但又缺乏一些关键信息时（例如，例子的类别），就可以利用EM。这使它在所有机器学习中成为最受欢迎的算法。</span></li><li><span class="name">一张脸大约有50块肌肉，因此50个数字足以用来描述所有可能的表情，而且还有很大的剩余空间。眼睛、鼻子、嘴巴等的样子（就是让你区分于别人的特点）的数量也不应该超过几十种。你可以添加几个数量，用来确定光线和姿态，这样就差不多了。因此如果你给我100多个数量，就已经足以重新构造一张脸部图片。</span></li><li><span class="name">机器学习算法称该过程为维数约简，因为该过程将大量的可见维度（像素）简化成几个隐性维度（表情、面部特征）。维数约简对于应对大数据（像每秒钟通过你的知觉而进入的数据）来说很关键。一张图可能抵得上1000个字，但要处理和记住所做的付出，却要高出100万倍。你的视觉皮质好歹把大数据削减为数量上可管理的信息，足以用来引导这个世界、识别人和物、记住你看见的东西。这是认知最伟大的奇迹之一，并且如此自然，你甚至意识不到自己正在做这些事。</span></li><li><span class="name">主要成分分析（principle–componentanalysis，PCA），是科学家的工具箱中关键的工具之一。</span></li><li><span class="name">心理学家已经发现，个性可以简化为5个维度（外向、随和、尽责、神经质、开放性），他们可以通过你的推特文章和博客帖子来进行推断。</span></li><li><span class="name">人类确实有稳定的向导：情感。我们追求快乐，躲避痛苦。</span></li><li><span class="name">棋盘游戏是强化学习问题的典范：你得走好多步棋，却得不到任何反馈，奖励或惩罚都在最后一刻揭晓，其形式也就是赢和输。IBM的塞缪尔的程序可以自学下棋，而且下得和大多数人一样好。它不会直接学棋盘上每步棋该怎么走，因为这太困难；相反，它会学习如何评价每个棋的位置（从该位置出发，赢的概率有多大），然后选择走能到达最佳棋位的那一步。起初，它知道如何进行评价的唯一位置就是最后的结果：赢、平局或是输。一旦它知道某个特定位置能赢，也就知道哪些位置有利于让它达到这个位置。</span></li><li><span class="name">（9）机器学习能干什么，不能干什么</span></li><li><span class="name">例子：</span></li><li><span class="name">例子1：看看曼彻斯特大学生物技术研究院的实验室，在那里，一个名叫亚当的机器人正在努力工作，目的是找到哪些基因在酵母中对哪些酶进行编码。亚当有一个酵母新陈代谢的模型，还掌握了基本的基因及蛋白质知识。它提出假设，设计实验验证假设，进行实地实验，分析结果，提出新的假设，直到它满意为止。</span></li><li><span class="name">例子2：奥巴马雇用了拉伊德·贾尼（机器学习专家，他是奥巴马竞选中的首席科学家）。贾尼研究的是如何整合最伟大的分析运算，并将其应用到政治史中。他们将所有选民的信息整合成单个数据库，然后将该数据库和他们能在社交网络、市场营销等领域找到的资源结合起来。之后着手对每个选民做四种预测：（1）支持奥巴马的可能性有多大；（2）会不会参加民意调查；（3）会不会回应竞选宣传并照做；（4）对特定问题进行对话之后，他们会不会改变选举决定。基于这些选民的例子，奥巴马团队每个晚上进行66000场选举模拟，并用这些结果指导奥巴马竞选的志愿者大军：该给谁打电话，该拜访谁，该说什么。</span></li></ul></li></ul></li><li><span class="name">基本概念</span><ul><li><span class="name">人工智能：一种旨在让计算机实现类似人类的智能，尤其是不能通过机械式计算完成的智能行为（智能本身也给出不准确的定义）的技术方案. 比如自动驾驶、文本处理、语言识别、图像识别等。</span></li><li><span class="name">机器学习：如果一个程序可以在任务T上，随着经验E的增加，效果P也可以随之增加，则称这个程序可以从经验中学习（卡耐基梅隆大学Mitchell教授，1997）。 经验E即训练集，效果P即模型的正确率。</span></li><li><span class="name">机器学习是“太阳底下的新鲜事”：一种能够构建自我的技术。在农业当中，我们播种，确保种子有足够的水分和营养，然后等待成熟, 最终收割成熟的作物。我们不需要控制作物生长的每一步。为什么技术不能这样？完全可以，而这也是机器学习的承诺。</span></li><li><span class="name">有些算法学习知识，有的则学习技能。</span><ul><li><span class="name">知识。在机器学习中，知识往往以统计模型的形式出现，因为多数知识都是可以统计的，比如所有人都会死，但只有4%是美国人。</span></li><li><span class="name">技能. 技能往往以程序的形式出现，表示一系列有一定关联的动作。</span></li></ul></li><li><span class="name">动物园比喻</span><ul><li><span class="name">在信息处理这个生态系统中，学习算法是<b>顶级掠食者</b>。</span></li><li><span class="name">数据库、网络爬虫、索引器等相当于<b>食草动物</b>，耐心地对无限领域中的数据进行蚕食。食草动物有必要存在，因为没有它们，其他动物无法存活，但顶级掠食者有更为刺激的生活。</span></li><li><span class="name">数据库就像<b>大象</b>，又大又重，永远不会被忽略。</span></li><li><span class="name">数据爬虫就像一头<b>牛</b>，网页相当于它的草原，每个网页就是一根草。索引器做一个页面的列表，每个词都会出现在页面当中，很像一本书后的索引。</span></li><li><span class="name">统计算法、线上分析处理等则相当于<b>食肉动物</b>。</span></li><li><span class="name">在这些动物当中，耐心的野兽飞快运转统计和分析算法，压缩并进行选择，将数据变为信息。</span></li><li><span class="name">学习算法是<b>顶级掠食者</b>, 它将这些信息吞下、消化，然后将其变成知识。</span></li></ul></li><li><span class="name"><b>深度学习（deep learning）</b>：是机器学习的一个分支，即深层神经网络。一种通过多层非线性变换对高复杂性数据建模的算法的合集。</span><ul><li><span class="name"><b>深度学习属于联结主义，</b>它在模拟人类大脑的神经元的联结方式. </span></li></ul></li><li><span class="name">训练（学习）：从数据中习得模型的过程。</span></li><li><span class="name">测试：学得模型后，使用其进行预测以检测其可信度的过程。</span></li><li><span class="name">数据集：在机器学习任务中使用的一组数据。一般包括训练集, 验证集, 测试集.</span></li><li><span class="name">样本：数据集中的每一个数据称为一个样本。</span></li><li><span class="name">训练集：训练过程中使用的数据集。</span></li><li><span class="name">验证集：用于调整参数。一般把原始数据拿出一小部分（10%-20%）作为验证数据。</span></li><li><span class="name">测试集：测试使用的另外一组数据集。测试集要和训练集隔离。</span></li><li><span class="name">特征：反映样本在某方面的表现或性质的事项或属性。样本由特征组成。</span></li><li><span class="name">特征向量（feature vector）：所有用于描述实体的数字的组合就是该实体的特征向量。是机器学习的输入.</span></li><li><span class="name"><b>回归</b>：机器学习的两个主要用途之一。计算机会对输入预测输出数字。学习算法通常会输出一个函数：f: R^n-&gt;R。比如预测股票价格。</span></li><li><span class="name"><b>分类</b>：机器学习的两个主要用途之一。即计算机会给出输入X属于k类中的哪一类。为了完成这个任务，学习算法通常会输出一个算法: f:R^n-&gt;{1, k}。比如图像分类就是一种分类任务。分类问题的本质是回归问题。</span></li><li><span class="name"><b>泛化</b>：机器学习的目标是使学得的模型能够很好的适用于未知样本，而不是仅仅在已知样本上工作得很好。模型适用于新样本的能力称为“泛化”能力。</span></li><li><span class="name">归纳偏置：我们一般都假定问题存在某种形式。</span></li><li><span class="name">归纳学习假设：任一假设如果在足够大的训练集中很好的逼近目标函数，它也能在未见样本中很好的逼近目标函数。</span></li></ul></li><li><span class="name"><b>监督学习</b></span><ul><li><span class="name">利用已知类别的样本（即有标记的样本, labeled sample），训练学习得到一个<b>分类</b>模型，使其能将新的输入分类。</span></li><li><span class="name">就是提供一堆选择题及其标准答案给计算机；然后计算机调整自己的模型参数，以使自己推测到的答案和标准答案越一致越好；等模型足够好，计算机就给出新数据的分类了。</span></li></ul></li><li><span class="name"><b>非监督学习</b></span><ul><li><span class="name">对于没有标记的样本，学习算法直接对输入数据进行建模，比如<b>聚类</b>，只要把相似度高的样本放在一起，对于新的数据样本计算其相似度后，安排相似度进行归类。</span></li><li><span class="name">算法不知道每一类是什么，但知道它们属于同类。</span></li></ul></li><li><span class="name"><b>半监督学习</b></span><ul><li><span class="name">让计算机自动对大量未标记数据进行学习，并辅助以少量有标记数据。</span></li></ul></li><li><span class="name"><b>强化学习</b></span><ul><li><span class="name">机器学习从环境到行为的学习，以使奖励信号（强化信号）函数最大化。</span></li><li><span class="name">强化学习不同于监督学习的地方在于强化信号是对<b>输出</b>信号的好坏的一种评价（通常称为标量信号），而不是作为输入数据的一部分。</span></li><li><span class="name">这里强调输入和输出意义不大, 实际上, 输入的结果就是输出. 真正的区别在于结果的形式: 监督学习给出的是对错的结果, 而强化学习给出的正确了百分之几这样的结果.</span></li><li><span class="name">打比方: 监督学习是选择题, 强化学习是问答题. 选择题只有对错. 问答题则可以对1%, 也可以对50%, 还可以对100%.</span></li><li><span class="name">和考试类似, 监督学习适用于基础知识, 强化学习适用于复杂场景. 监督学习快捷简单, 结论一目了然, 题目出好了, 老师水平高低几乎无所谓; 强化学习则如同一种艺术, 能适应所有知识场景, 但对老师的水平要求高.</span></li></ul></li><li><span class="name">早期算法</span><ul><li><span class="name">线性回归（LR）：最简单的模型，但是效果不错，所以非常重要。对于 X=(x1, x2,&nbsp;…,xn)^T 属于 R^(n*p) 表示数据矩阵，其中 xi 属于 R^p 表示一个P维的数据样本； Y=(y1, y2,&nbsp;… ,yn)^T 属于 R^n 表示数组的label，这里只考虑每个样本一类的情况。线性回归的模型是：对于一个样本xi，它的输出值是其特征向量的线性组合：</span><ul><li><span class="name">其中 W0 为bias，即偏置。也可以通过x0=1 把W0纳入表达式中。总之，xi有P+1个维度。</span></li><li><span class="name">线性模型的最大特点是任意线性模型的组合仍然是线性模型。因此，只通过线性模型，任何层的全连通神经网络和单层神经网络的表达能力没有区别。</span></li></ul></li><li><span class="name">最小均方误差法（LMS，least mean squares）：</span><ul><li><span class="name">我们要寻求一个策略，逐步改进V(b)的各权值，使E最小化。E又称为误差函数或损失函数。</span></li></ul></li><li><span class="name">支持向量机（SVM）：传统的机器学习的方法。90年代中期到20世纪头10年非常火，目前已式微。是一种二分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器。SVM包括核技巧，这使它成为实质上的非线性分类器。SVM是求解二次规划问题的最优算法。</span></li><li><span class="name">GMM模型：混合高斯模型。传统机器学习模型。目前已式微。</span></li><li><span class="name">决策树：较有效的决策树算法包括 ID3、C4.5、CART。</span></li><li><span class="name">朴素贝叶斯算法（Naive Bayes）：朴素即特征条件独立（正交）。贝叶斯定理：P(y|x) = P(x|y)*P(y) / P(x)。</span></li><li><span class="name">K近邻算法（KNN）：分类算法，较成熟和有效。该方案的思路是：如果一个样本在特征空间中的K个最相似（即在特征空间中最邻近）的样本中的大多数属于一个类别，则该样本也属于这个类别。</span></li><li><span class="name">感知器（Perceptron/PLA）：一种完成分类的模型，模拟人类大脑神经元结构，通过N个权重来计算N个输入值的加权和，然后通过一个阈值函数得到0或1的输出。感知器即单层神经网络，也即没有隐层的神经网络。目前已经势微。</span><ul><li><span class="name">感知器的优势在于自动通过学习来调整权重。它的弱点是只能把数据分为两类，而且数据必须是线性可分的。</span></li><li><span class="name">感知器可以表示为 f: R^n → {−1,1} 的映射函数。其中 f 的形式如下：f(x)=sign(w.x+b)</span></li><li><span class="name">x是输入数据。w 和 b 都是 N 维向量，是感知器的模型参数；其中W是权值，b是偏置（bias）。感知器的训练过程其实就是求解w 和 b 的过程。正确的 w 和 b 所构成的超平面 w.x+b=0 恰好将两类数据点分割在这个平面的两侧。此时-b可看成是正类的阈值。</span></li><li><span class="name">感知器最大的问题是无法模拟异或运算。</span></li></ul></li></ul></li><li><span class="name">卷积神经网络</span><ul><li><span class="name">深度：即深度神经网络的隐层的数量。理论上越深越好，即层数越多越好。</span></li><li><span class="name">学习率（learning rate）:参见梯度下降。</span></li><li><span class="name">神经网络（NN/ANN）：神经网络中的每个神经元的模型叫 Logistic回归模型，如下：</span><ul><li><span class="name">其公式是：</span></li><li><span class="name">多层神经元组成神经网络。如下：</span></li></ul></li><li><span class="name">隐层：又叫隐藏层，神经网络中介入输入层和输出层之间的层统一称为隐层。</span></li><li><span class="name">激活函数：神经网络是通过海量（但还是有限个）的线性方程和简单非线性方程（比如x^2、x1x2、sin(x)等）来拟合复杂非线性关系，当然这里的海量是真海量，一般是10^10这种量级。但是很难数学证明这些方程具有正交性，所以要防备它们手拉手掉进坑里。怎么办呢？加一个非线性方程，这个方程就叫激活函数，也就是鲶鱼，在大家都疲倦下来时由它提供跳出大坑（即局部最优解）的可能性。</span></li><li><span class="name">反向传播(BP): 将神经网络的输出信息和理想的输出信息相比，会得出误差信号，这个信号会穿过神经元层反向传播回去，直到它到达输入层。根据返回来的信号以及在前进过程中它接收到的输入信息，每个神经元会调整各自的权值。</span><ul><li><span class="name">有了反向传播，你就不必逐个对神经元的权值进行微调，这样很慢。你可以一层一层来做，根据调整与其相连神经元的方法，来调整每个神经元。其算法是：</span></li><li><span class="name">对于每一个训练样本&lt;x, t&gt;，使用当前权重计算输出o；</span></li><li><span class="name">对于每一个权重wi做如下的更新：</span></li><li><span class="name">wi = wi +&nbsp;Δwi； 其中Δwi =&nbsp;η [t - o]xi</span></li><li><span class="name">其中X为输入向量，W为权重向量，xi 和 wi 为X和W的第i个元素。T为目标值，O为当前权值下的输出，η 为学习率。</span></li></ul></li><li><span class="name">损失函数(lost funciton)：反映神经网络预测输出和实际输出之间的误差。最常用的损失函数是L2.</span><ul><li><span class="name">其中：d为训练样本，D为训练集；td为预测输出，od为实际输出。</span></li></ul></li><li><span class="name">梯度下降（Gradient Descent/GD）：即用迭代的方法以最小化模型误差的参数优化算法，用于解决反向传播的下降多少的问题。梯度下降法通过多次迭代，并在每一步中最小化损失函数来估计模型的参数（weights）。通俗说就是一次下一格，而不是一点点的挪动。其公式是：</span><ul><li><span class="name">ωj+1&nbsp;=&nbsp;ωj&nbsp;-&nbsp;λ&nbsp;∂F(ωj) /&nbsp;∂ωj</span></li><li><span class="name">ωj&nbsp;是模型参数， F(ωj)是损失函数， ∂F(ωj) /&nbsp;∂ωj&nbsp;是ωj&nbsp;&nbsp;的一阶导数，λ&nbsp;是学习率(确定每次“跳”的阶梯的高度)。</span></li><li><span class="name">如果F(ωj)是单调函数，经过多次迭代会得到最小的成本函数；如果F(ωj)非单调，那么我们有可能陷入局部最优，一个简单的解决办法是通过多次尝试不同的ωj 初始值，对比不同估计参数下的成本函数的值是否一致，来发现是否陷入局部最优。</span></li><li><span class="name">梯度向量的方向指向损失函数增长最快的方向，负梯度向量-f则指向函数下降最快的方向。</span></li></ul></li><li><span class="name">深度神经网络（DNN）</span><ul><li><span class="name">深度神经网络强大的原因是它的隐层天然具有提取特征的能力。层次越多，提取的特征维度越高，抽象能力越强。</span></li><li><span class="name">深度没有具体指标，一般问题超过4层就算“挺深的”，而图形识别中一般有20层以上。</span></li><li><span class="name">2006年，Hinton利用预训练方法缓解了局部最优解问题，将隐层推到了7层，开启了深度神经网络的大门。</span></li><li><span class="name">如果层次过多，“<b>梯度消失</b>”现象会非常严重。我们通常用sigmoid作为神经元的输入输出函数。对于幅度为1的信号，在BP方向梯度传播时，每多传递一层，梯度衰减为原来的25%。层次越多，梯度衰减得越厉害，越难受到有效的训练信号。</span></li><li><span class="name">2016年出现的高速公路网络和深度残缺学习则进一步避免了梯度消失的问题，层次超过了100多层（深度残缺学习达到了152层）。</span></li></ul></li><li><span class="name">卷积神经网络（CNN）：由一个或多个卷积层和顶端的全连通图（对应经典的神经网络）组成同时也包括关联权重和池化层（pooling layer）。这一结构使得CNN能够输入数据的二维结构，与其他算法相比，CNN在图像应用上更占优势。对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重，因为每个神经元的权重固定，所以可看做是一个恒定的滤波器filter，也叫卷积核）做内积（逐个元素相乘再求和）的操作就是“卷积”操作。如下图:</span><ul><li><span class="name">CNN的示意图  <span class="contentTag" title="Filter #Chart">#<span class="contentTagText">Chart</span><span class="contentTagNub"></span></span> </span></li><li><span class="name">注意上图中3个矩阵的规模的关系:a=b+c-1。</span></li><li><span class="name">CNN的优势是保留局部秩序，既不影响特征提取（假设如此），又极大的降低了一般的深度神经网络（全连通图）的参数暴涨问题。CNN在图像、语音领域优势非常明显，因为这些领域的数据具有明显的局部秩序。</span></li></ul></li></ul></li><li><span class="name">循环神经网络（RNN）和LSTP模型</span><ul><li><span class="name">换句话说，RNN是一个在时间上传播的神经网络，它的深度就是时间的长度（这个模型肯定能启发人类对时间的本质的认识）。</span></li><li><span class="name">深度神经网络存在一个问题，无法对时间序列上的变化进行建模。</span></li><li><span class="name">为解决这一点，需要让各神经元的输出在下一个时间戳上作用到自身，即第i层神经元在m时刻接受到的输入，除了i-1层神经元在m时刻的输出外，还包括自身在m-1时刻的输出。这就是RNN。</span></li><li><span class="name">LSTP至今都是自然语言处理、语音识别、机器翻译等领域的最好模型。</span></li><li><span class="name">长短时记忆单元（LSTM）：RNN会有梯度消失的问题，对于T时刻来说，它产生的梯度在时间轴向后传播几层就消失了，无法影响太久的将来。LSTM就是为了解决这个问题，通过开关实现记忆功能，防止梯度消失。</span></li><li><span class="name">LSTP模型：1991年提出，可有效对较长序列进行建模，比如一句话或一段文字。</span></li><li><span class="name">还有更有趣的，比如预测未来一定对认识现在有价值，所以就有了双向RNN、双向LSTM，同时利用历史和未来的信息。</span></li></ul></li><li><span class="name">自然语言处理(NLP)</span><ul><li><span class="name">word2vec: 词向量</span><ul><li><span class="name">目的: 找出词与词之间的关系. </span></li><li><span class="name">输出: 词料库中任意两个词出现在同一句话的概率, 比如 (中国, 韭菜) 的概率大于(中国, 蝈蝈). </span></li><li><span class="name">可选两个模型: CBOW 和 skip-Gram</span></li><li><span class="name">CBOW: 训练输入是特征词的上下文相关的词的对应的词向量, 输出是该词的词向量.</span></li><li><span class="name">CBOW 适用于小型词料库. </span></li><li><span class="name">skip-Gram的思路则相反, 输入是词向量, 输出是该词的上下文词向量.</span></li><li><span class="name">skip-Gram适用于大型词料库. </span></li></ul></li></ul></li><li><span class="name"><b>误差及解决方案</b></span><ul><li><span class="name">误差：学得的模型在样本上的预测结果与样本的真实结果之间的差异称为误差。</span></li><li><span class="name">训练误差：在训练集上的误差。</span></li><li><span class="name">泛化误差：在新样本上的误差。我们希望得到泛化误差小的模型。</span></li><li><span class="name">过拟合（overfitting）：如果模型的训练误差小，而泛化误差大，则称为过拟合。</span></li><li><span class="name">欠拟合（underfitting）：如果训练误差和泛化误差都较大，则称为欠拟合。</span></li><li><span class="name">机器学习的性能评估指标（针对分类问题）：</span><ul><li><span class="name">True Negative(真负，TN)：将负类预测为负类的数量；</span></li><li><span class="name">True Positive(真正，TP)：将正类预测为正类的数量；</span></li><li><span class="name">False Positive(假正，FP)：将负类预测为正类的数量（误报，type 1 error）</span></li><li><span class="name">False Negative（假负，FP）：将负类预测为正类的数量（漏报，type 2 error）</span></li></ul></li><li><span class="name">精确度（Prevision）： P = TP / (TP+FP)</span></li><li><span class="name">召回率（recall）：R = TP / (TP+TN)</span></li><li><span class="name">准确率（accuracy）：ACC = (TP+TN) / (TP+TN+FP+FN)</span></li><li><span class="name">F1值： F1 = 2TP / (2TP+FP+FN)</span></li><li><span class="name"><b>批标准化</b></span><ul><li><span class="name">目的: 加大梯度. </span></li><li><span class="name">优点是:</span></li><li><span class="name">1. 加大检索的步长, 加快收敛;</span></li><li><span class="name">2. 更容易跳出局部最小值;</span></li><li><span class="name">3. 破坏原来的数据分布. 一定程度上缓解了过拟合. </span></li></ul></li></ul></li></ul>
  </body>
</html>